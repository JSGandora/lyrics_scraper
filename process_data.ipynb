{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP IMPORTS\n",
    "\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import networkx as nx\n",
    "\n",
    "GENERATE_DATA = False\n",
    "GENRES = [\"blues\", \"gospel\", \"rap\", \"country\", \"rock\"]\n",
    "DATA_DIR = \"/n/fs/guoweis-18iw/get_data/lyrics\"\n",
    "\n",
    "if GENERATE_DATA:\n",
    "    # Read data\n",
    "    df = pd.DataFrame(np.nan, index=[], columns=['artist', 'title', 'album', 'year', 'lyrics', 'genre'])\n",
    "\n",
    "    ct = 0\n",
    "    for genre in GENRES:\n",
    "        genre_dir = join(DATA_DIR, genre)\n",
    "        fns = listdir(genre_dir)\n",
    "        for i, fn in enumerate(fns):\n",
    "            if i % 10 == 0:\n",
    "                print(\"Done with \" + str(i) + \" of \" + str(len(fns)) + \" files.\")\n",
    "            fp = join(genre_dir, fn)\n",
    "            data_str = open(fp).read()\n",
    "            data = json.loads(data_str)\n",
    "            songs_data = data[\"songs\"]\n",
    "            for j, song in enumerate(songs_data):\n",
    "                df.loc[ct, \"genre\"] = genre\n",
    "                for key in song.keys():\n",
    "                    if key == \"raw\" or key == \"image\":\n",
    "                        continue\n",
    "                    df.loc[ct, key] = song[key]\n",
    "                ct += 1\n",
    "        df.to_pickle(genre + \".data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "ALL_DATA_FN = \"all.data\"\n",
    "df = pd.read_pickle(ALL_DATA_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data\n",
    "df[\"randn\"] = np.random.uniform(0, 1, df.shape[0])\n",
    "df[\"data_split\"] = np.array([\"test\" if n > 0.8 else \"train\" for n in df[\"randn\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire Dataset\n",
      "{'rock': 16089, 'country': 16188, 'rap': 10902, 'gospel': 9086, 'blues': 7146}\n",
      "Training Set\n",
      "{'rock': 12817, 'country': 12986, 'rap': 8733, 'gospel': 7305, 'blues': 5671}\n",
      "Test Set\n",
      "{'rock': 3272, 'country': 3202, 'rap': 2169, 'gospel': 1781, 'blues': 1475}\n"
     ]
    }
   ],
   "source": [
    "# Get label distributions of training and test sets\n",
    "def get_distribution(labels):\n",
    "    ct = {}\n",
    "    for lab in labels:\n",
    "        if lab in ct:\n",
    "            ct[lab] += 1\n",
    "        else:\n",
    "            ct[lab] = 1\n",
    "\n",
    "    return ct\n",
    "\n",
    "# Calculate dataset statistics\n",
    "print(\"Entire Dataset\")\n",
    "print(get_distribution(df[\"genre\"]))\n",
    "print(\"Training Set\")\n",
    "print(get_distribution(df.query(\"data_split == 'train'\")[\"genre\"]))\n",
    "print(\"Test Set\")\n",
    "print(get_distribution(df.query(\"data_split == 'test'\")[\"genre\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.981651376146789\n",
      "5.45\n",
      "20\n",
      "109\n",
      "13\n",
      "{'reason', 'way', 'here', 'be', 'honey,', 'all', 'then', \"i'm\", 'know,', 'as', 'babe', 'deep', 'just', 'drivin', 'babi', 'ya', 'down', 'string', 'need', 'well,', 'that', 'a-yeah,', 'you', 'hurt', 'darlin', 'tell', 'cryin', 'your', 'a-just', 'what', 'dri', 'the', 'to', 'tie', 'want', 'crazy,', 'and', 'string,', 'we', 'stop', 'it', 'never', 'come', 'crazi', 'part', 'a-honey,', 'i', 'girl,', 'know', 'a', 'so', 'around', 'sweet', 'would', \"i'll\", 'eye', 'insid', 'me', 'ta', 'yeah,', 'heart', 'goin', 'can', 'a-honey'}\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "ACCEPTED_CHARS = set('abcdefghijklmnopqrstuvwxyz \\'\\n')\n",
    "def lyrics_strip(lyrics):\n",
    "    verse = lyrics.strip().lower()\n",
    "    verse = ''.join(filter(ACCEPTED_CHARS.__contains__, verse))\n",
    "    return verse\n",
    "\n",
    "def lyrics_to_linelist(lyrics):\n",
    "    lyrics = lyrics.split(\"\\n\")\n",
    "    lyrics = [line.split() for line in lyrics]\n",
    "    return lyrics\n",
    "\n",
    "def linelist_to_wordlist(lines):\n",
    "    return [word for line in lines for word in line]\n",
    "\n",
    "def lyrics_to_wordlist(lyrics):\n",
    "    return lyrics.split()\n",
    "\n",
    "def avg_word_len(lyrics):\n",
    "    wordlist = lyrics_to_wordlist(lyrics)\n",
    "    lengths = [len(word) for word in wordlist]\n",
    "    return sum(lengths)/len(lengths)\n",
    "\n",
    "def avg_line_len(lyrics):\n",
    "    linelist = lyrics_to_linelist(lyrics)\n",
    "    lengths = [len(line) for line in linelist]\n",
    "    return sum(lengths)/len(lengths)\n",
    "\n",
    "def total_num_lines(lyrics):\n",
    "    linelist = lyrics_to_linelist(lyrics)\n",
    "    return len(linelist)\n",
    "\n",
    "def total_num_words(lyrics):\n",
    "    wordlist = lyrics_to_wordlist(lyrics)\n",
    "    return len(wordlist)\n",
    "\n",
    "def num_contractions(lyrics):\n",
    "    wordlist = lyrics_to_wordlist(lyrics)\n",
    "    return sum([1 if \"\\'\" in word else 0 for word in wordlist])\n",
    "\n",
    "def num_contractions(lyrics):\n",
    "    wordlist = lyrics_to_wordlist(lyrics)\n",
    "    return sum([1 if \"\\'\" in word else 0 for word in wordlist])\n",
    "\n",
    "def vocab(lyrics):\n",
    "    wordlist = lyrics_to_wordlist(lyrics)\n",
    "    wordlist = [stemmer.stem(word) for word in wordlist]\n",
    "    return set(wordlist)\n",
    "\n",
    "def vocab_size(lyrics):\n",
    "    return len(vocab(lyrics))\n",
    "\n",
    "lyrics = df.loc[1,\"lyrics\"]\n",
    "linelist = lyrics_to_linelist(lyrics)\n",
    "wordlist = linelist_to_wordlist(linelist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rhyme features\n",
    "### Adapted from https://github.com/edwadli/rapgraph/blob/master/src/rapper.py\n",
    "from nltk.corpus import cmudict\n",
    "transcr = cmudict.dict()\n",
    "_NULL_ = '_NULL_'\n",
    "phs = 'AA AE AH AO AW AY B CH D DH EH ER EY F G HH IH\\\n",
    "    IY JH K L M N NG OW OY P R S SH T TH UH UW V W Y Z'.split()\n",
    "phs_vowels = set('AA AE AH AO AW AY EH ER EY IH IY OW OY UH UW'.split())\n",
    "\n",
    "def phonemes(words):\n",
    "    words = [word.lower() for word in words]\n",
    "    phonemes = {}\n",
    "    for word in words:\n",
    "        # get possible pronunciations from dict\n",
    "        possible_pronunciations =  transcr.get(word, [[_NULL_]])\n",
    "        if word not in transcr:\n",
    "            # TODO: generate a guess on the pronunciation\n",
    "            pass\n",
    "        # strip out emphasis on vowels\n",
    "        for pronunciation in possible_pronunciations:\n",
    "            for i in range(len(pronunciation)):\n",
    "                pronunciation[i] = ''.join(c for c in pronunciation[i] if not c.isdigit())\n",
    "        # remove repeats\n",
    "        possible_pronunciations = list(set([tuple(p) for p in possible_pronunciations]))\n",
    "        phonemes[word] = possible_pronunciations\n",
    "    return phonemes\n",
    "\n",
    "def phonemeSimilarity(ph_a, ph_b):\n",
    "    # Heuristic phoneme rhyming similarity in range [0, 1]    \n",
    "    relative_score = 0.\n",
    "    if ph_a == _NULL_ or ph_b == _NULL_:\n",
    "        return 0.\n",
    "    if ph_a == ph_b:\n",
    "        # rhyme\n",
    "        relative_score = 1.\n",
    "    elif ph_a in phs_vowels:\n",
    "        if ph_b in phs_vowels:\n",
    "            # both vowels, likely to rhyme\n",
    "            relative_score = 0.3\n",
    "    elif ph_b not in phs_vowels:\n",
    "        # both consonants, could help rhyme\n",
    "        relative_score = 0.05\n",
    "    return relative_score\n",
    "\n",
    "def alignPhonemeSequences(a_seq, b_seq):\n",
    "    # Smith-Waterman alignment with custom phoneme similarity scoring\n",
    "    GAP_PENALTY = -1.\n",
    "    MIN_SCORE = -10.\n",
    "    MAX_SCORE = 10.\n",
    "    score_range = MAX_SCORE - MIN_SCORE\n",
    "    width = len(a_seq)+1\n",
    "    height = len(b_seq)+1\n",
    "    H = [[0] * width for i in range(height)]\n",
    "    \n",
    "    # Run the DP alg\n",
    "    for row in range(1,height):\n",
    "        for col in range(1,width):\n",
    "            relative_score = phonemeSimilarity(a_seq[col-1], b_seq[row-1])\n",
    "            align = H[row-1][col-1] + relative_score * score_range + MIN_SCORE\n",
    "            deletion = H[row-1][col] + GAP_PENALTY\n",
    "            insertion = H[row][col-1] + GAP_PENALTY\n",
    "            H[row][col] = max(0, align, deletion, insertion)\n",
    "\n",
    "    # extract the solution\n",
    "    # find max value in H\n",
    "    max_value = 0\n",
    "    max_row = None\n",
    "    max_col = None\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            if H[row][col] >= max_value:\n",
    "                max_value = H[row][col]\n",
    "                max_row = row\n",
    "                max_col = col\n",
    "    return max_value, H\n",
    "\n",
    "def end_rhyme_score(a_seq, b_seq):\n",
    "    max_val, h = alignPhonemeSequences(a_seq, b_seq)\n",
    "    return h[-1][-1]\n",
    "\n",
    "def aligned_rhyme_score(a_seq, b_seq):\n",
    "    max_val, h = alignPhonemeSequences(a_seq, b_seq)\n",
    "    return max_val\n",
    "\n",
    "def aligned_matrix(a_seq, b_seq):\n",
    "    max_val, h = alignPhonemeSequences(a_seq, b_seq)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "29929\n",
      "[ 0. 14. 16. 18. 19. 20. 30. 40.]\n",
      "113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([40., 30., 40., 30., 20., 30., 20., 30., 20., 20., 30., 30., 20.,\n",
       "       20., 30., 30., 20., 20., 30., 20., 30., 20., 30., 20., 30., 18.,\n",
       "       20., 30., 30., 18., 14., 20., 14., 20., 19., 19., 20., 19., 20.,\n",
       "       30., 19., 30., 20., 30., 30., 30., 30., 30., 20., 20., 30., 30.,\n",
       "       30., 20., 30., 20., 20., 30., 20., 20., 18., 20., 18., 20., 30.,\n",
       "       30., 20., 30., 30., 30., 30., 30., 20., 20., 30., 30., 30., 20.,\n",
       "       30., 20., 20., 30., 20., 20., 20., 20., 18., 18., 18., 16., 20.,\n",
       "       20., 20., 20., 20., 18., 16., 20., 20., 20., 20., 20., 20., 20.,\n",
       "       30., 30., 20., 30., 30., 30., 30., 30., 20., 20., 30., 30., 30.,\n",
       "       20., 30., 20., 20., 30., 20., 20.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get line adjacency graph\n",
    "\n",
    "def get_rhyme_adj_graph(lyrics, thresh = 0):\n",
    "    linelist = lyrics_to_linelist(lyrics)\n",
    "    wordlist = lyrics_to_wordlist(lyrics)\n",
    "    get_phonemes = phonemes(wordlist)\n",
    "    num_wrds = len(wordlist)\n",
    "    graph = np.zeros((num_wrds, num_wrds))\n",
    "    \n",
    "    i = 0\n",
    "    for j, line in enumerate(linelist):\n",
    "        full_phrase = line\n",
    "        if j < len(linelist)-1:\n",
    "            full_phrase = linelist[j] + linelist[j+1]\n",
    "        for k, word in enumerate(line):\n",
    "            word1 = word\n",
    "            for l, word2 in enumerate(full_phrase[k+1:]):\n",
    "                ph1 = get_phonemes[word1]\n",
    "                ph2 = get_phonemes[word2]\n",
    "                w = 0\n",
    "                for p1 in ph1:\n",
    "                    for p2 in ph2:\n",
    "                        w = max(w, aligned_rhyme_score(p1, p2))\n",
    "                graph[i, i+1+l] = w\n",
    "                graph[i+1+l, i] = w\n",
    "            i += 1\n",
    "    graph[graph <= thresh] = 0\n",
    "    return graph\n",
    "\n",
    "lyrics = lyrics_strip(df.loc[0, \"lyrics\"])\n",
    "g = get_rhyme_adj_graph(lyrics, 10)\n",
    "\n",
    "G = nx.from_numpy_matrix(g)\n",
    "\n",
    "print(np.count_nonzero(g))\n",
    "print(np.size(g))\n",
    "print(np.unique(g))\n",
    "\n",
    "print(nx.number_connected_components(G))\n",
    "\n",
    "def edge_density(rhyme_graph, weighted=False):\n",
    "    if weighted:\n",
    "        return np.sum(rhyme_graph)/np.size(rhyme_graph)\n",
    "    return np.count_nonzero(rhyme_graph)/np.size(rhyme_graph)\n",
    "\n",
    "def edge_var(rhyme_graph):\n",
    "    return np.var(rhyme_graph[rhyme_graph > 0])\n",
    "\n",
    "def degree_var(rhyme_graph, weighted=False):\n",
    "    if weighted:\n",
    "        degrees = [np.sum(vertex) for vertex in rhyme_graph]\n",
    "    else:\n",
    "        degrees = [np.count_nonzero(vertex) for vertex in rhyme_graph]\n",
    "    return np.var(degrees)\n",
    "\n",
    "def degree_avg(rhyme_graph, weighted=False):\n",
    "    if weighted:\n",
    "        return np.sum(rhyme_graph)/len(rhyme_graph)\n",
    "    return np.count_nonzero(rhyme_graph)/len(rhyme_graph)\n",
    "\n",
    "def comp_size_avg(rhyme_graph):\n",
    "    return len(rhyme_graph)/nx.number_connected_components(nx.from_numpy_matrix(rhyme_graph))\n",
    "\n",
    "def num_comp(rhyme_graph):\n",
    "    return nx.number_connected_components(nx.from_numpy_matrix(rhyme_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"randn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
